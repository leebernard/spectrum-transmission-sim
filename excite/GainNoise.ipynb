{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from astropy import units as u\n",
    "from astropy.modeling.physical_models import BlackBody as BB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read TepCat\n",
    "\n",
    "This step is needed to have a database of transiting GP to read parameters from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tepcat-allplanets-csv.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-db2f4acae11c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mastropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mascii\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mColumnNames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mascii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tepcat-allplanets-csv.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mTepCat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mascii\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tepcat-allplanets-csv.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTC_col\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mColumnNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTepCat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/astropy/io/ascii/ui.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(table, guess, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;31m# through below to the non-guess way so that any problems result in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# more useful traceback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_guess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfast_reader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0mguess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/astropy/io/ascii/ui.py\u001b[0m in \u001b[0;36m_guess\u001b[0;34m(table, read_kwargs, format, fast_reader)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             _read_trace.append({'kwargs': copy.deepcopy(guess_kwargs),\n\u001b[1;32m    449\u001b[0m                                 \u001b[0;34m'Reader'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/astropy/io/ascii/core.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, table)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0;31m# Get a list of the lines (rows) in the table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;31m# Set self.data.data_lines to a slice of lines contain the data rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/astropy/io/ascii/core.py\u001b[0m in \u001b[0;36mget_lines\u001b[0;34m(self, table, newline)\u001b[0m\n\u001b[1;32m    303\u001b[0m             if (hasattr(table, 'read')\n\u001b[1;32m    304\u001b[0m                     or ('\\n' not in table + '' and '\\r' not in table + '')):\n\u001b[0;32m--> 305\u001b[0;31m                 with get_readable_fileobj(table,\n\u001b[0m\u001b[1;32m    306\u001b[0m                                           encoding=self.encoding) as fileobj:\n\u001b[1;32m    307\u001b[0m                     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/astropy/utils/data.py\u001b[0m in \u001b[0;36mget_readable_fileobj\u001b[0;34m(name_or_obj, encoding, cache, show_progress, remote_timeout, sources, http_headers)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremote_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 http_headers=http_headers)\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_url\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mdelete_fds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tepcat-allplanets-csv.csv'"
     ]
    }
   ],
   "source": [
    "from astropy.io import ascii\n",
    "\n",
    "ColumnNames = ascii.read('tepcat-allplanets-csv.csv', data_start=0, data_end=1, )[0]\n",
    "TepCat = ascii.read('tepcat-allplanets-csv.csv', data_start=1)\n",
    "for column_name, TC_col in zip(ColumnNames, TepCat.colnames):\n",
    "    if 'err' in column_name: \n",
    "        TepCat.remove_column(TC_col)\n",
    "    else:\n",
    "        TepCat[TC_col].name = column_name\n",
    "del ColumnNames\n",
    "TepCat.add_index('System')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "1. Select a favourable target such as WASP-121b or similar\n",
    "2. We will need the orbital period in seconds. So I convert period from days to seconds\n",
    "3. Calculate a simple estimate of the eclipse depth, and use this as the peak-to-peak amplitude of the phase curve signal model.\n",
    "4. The measured signal vs time is proportional to $F_s + F_p$, normalised to $F_s$, i.e. $1 + F_p/F_s$. In what follows, model is $F_p/F_s$\n",
    "5. I also add a phase shift, that can be randomised in a further iteration of this work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = 'WASP-121'\n",
    "phase = 0.2*np.pi\n",
    "\n",
    "system = TepCat.loc[Name]\n",
    "system['Period'] *= u.day.to(u.s)\n",
    "PlanetSED = BB(temperature=system['Teq']*u.K, scale = 1*u.W/u.m**2/u.sr/u.micron)\n",
    "StarSED   = BB(temperature=system['Teff']*u.K, scale = 1*u.W/u.m**2/u.sr/u.micron)\n",
    "\n",
    "eclipse_depth = (system['R_b']*u.Rjup.to(u.m)/(system['R_A']*u.Rsun.to(u.m)))**2 * \\\n",
    "            PlanetSED(2.2*u.micron)/StarSED(2.2*u.micron)\n",
    "eclipse_depth = eclipse_depth.value\n",
    "\n",
    "delta_t = 60.0 # seconds->days\n",
    "tt = np.arange(0, system['Period'], delta_t)\n",
    "\n",
    "model  = 0.5*eclipse_depth*np.sin(2*np.pi*tt/system['Period'] + phase) \n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 5))\n",
    "ax.plot(tt/3600, model)\n",
    "ax.set_ylabel('Model')\n",
    "ax.set_xlabel('Time [h]')\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline simulation\n",
    "\n",
    "Here I want to lay down the simulation procedure on a simple case. That is\n",
    "1. Run \"Nsim\" simulations\n",
    "2. Each simulation is an observation, corresponding to a timeline constructed from adding white noise to the true value of the signal (the model). \n",
    "3. I use a noise drawn from a Gaussian distribution with zero mean, and a $\\sigma = 0.1$%, that can be replaced with an ExoRad estimate. \n",
    "4. I then leas-square fit each of the Nsim simulation using a linear model:\n",
    "$$ model = a \\sin(2\\pi t/P) + a\\sin(2\\pi t/P) + b \\sin(2\\pi t/P) + c$$\n",
    "where $a$, $b$, and $c$ are the model parameters\n",
    "5. The ensamble distribution of the amplitude and phase are\n",
    "$$ A = \\sqrt{a^2 + b^2}$$\n",
    "$$ \\phi = \\arctan(a/b)$$\n",
    "6. I can then calculate the statistics:\n",
    "    - $\\bar A = {\\rm average}(A)$\n",
    "    - $\\sigma = {\\rm stdev}(A)$\n",
    "    - SNR = ${\\bar A}/\\sigma$\n",
    "    \n",
    "   and similar for the phase.\n",
    "7. I can also see if there is a statistically significant bias (significant here means given the precision of the simulation\n",
    "$$ {\\rm bias} = \\frac{ {\\rm EclipseDepth}/2 - {\\bar A}}{ {\\rm EclipseDepth}/2} $$\n",
    "to be compared with the significance of this bias estimate, i.e.\n",
    "$$ {\\rm Error}(\\rm bias) = \\frac{ {\\rm Error}(\\bar A)}{{\\rm EclipseDepth}/2} = \\frac{ \\sigma/\\sqrt{Nsim}}{{\\rm EclipseDepth}/2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsim = 1024     # this many simulations\n",
    "noise_std =1e-3 # this value to be replaced with ExoRad's estimate\n",
    "\n",
    "# Repeat Nsim independent observations adding noise to each\n",
    "# Observations are stored in D1's first dimension\n",
    "D1  = np.zeros( (Nsim, tt.size) ) + model\n",
    "D1 += np.random.randn( *D1.shape )*noise_std\n",
    "\n",
    "# Least-square fit the data\n",
    "A = np.c_[np.sin(2*np.pi*tt/system['Period']), \n",
    "          np.cos(2*np.pi*tt/system['Period']), \n",
    "          np.ones(tt.size)]\n",
    "\n",
    "par, *_ = np.linalg.lstsq(A, D1.T, rcond=-1)\n",
    "\n",
    "# Calculate statistics\n",
    "amplitude = np.sqrt( par[0]**2 + par[1]**2)\n",
    "amplitude_mean = amplitude.mean()\n",
    "amplitude_std  = amplitude.std()\n",
    "amplitude_snr  = amplitude_mean/amplitude_std\n",
    "amplitude_bias = (0.5*eclipse_depth - amplitude_mean)/(0.5*eclipse_depth)\n",
    "amplitude_bias_error = amplitude_std/(0.5*eclipse_depth)/np.sqrt(amplitude.size)\n",
    "TITLE = 'SNR = {:.0f};  BIAS = ({:.2f} +/- {:.2f})%'.format(amplitude_snr, \n",
    "                                           100*amplitude_bias,\n",
    "                                           100*amplitude_bias_error)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 5))\n",
    "ax.hist(100*amplitude)\n",
    "ax.set_xlabel('Amplitude [%]')\n",
    "ax.set_title(TITLE)\n",
    "ax.vlines(0.5*eclipse_depth*100, *ax.get_ylim(), color='r')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temperature-dependent trend\n",
    "\n",
    "We want to model a temperature-dependent trend. Best proxy I have so far is the temperature of M1 and M2 of the BlastPol telescope during its Antarctic flight in 2013.\n",
    "\n",
    "I use the mean of these two, in units of Centigrades\n",
    "\n",
    "BlastPol housekeepings were sampled at 5Hz. Our simulation runs with a cadence of 60 s. \n",
    "\n",
    "Therefore I average the BlastPol HK 60s by 60s. This is technically achieved using a technique called filter-and-decimate, that works as follow\n",
    "1. Box-car filter the data (sometimes called moving-average), with a kernel that 60 s long. \n",
    "2. Take one sample every 60 s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M1 temperature\n",
    "TM1 = np.fromfile('t_prime_sf', dtype=np.uint16)\n",
    "TM1 = 2.840909090909e-02*TM1 -2.731500000000e+02\n",
    "# M2 temperature\n",
    "TM2 = np.fromfile('t_second_sf', dtype=np.uint16)\n",
    "TM2 = 2.840909090909e-02*TM2 -2.731500000000e+02\n",
    "\n",
    "TM = 0.5*(TM1+TM2)\n",
    "blast_time = np.arange(TM.size)/5.0\n",
    "\n",
    "# Cut away firs two days worth of data as it contains glitches\n",
    "TM = TM[864000:]\n",
    "blast_time = blast_time[864000:]\n",
    "\n",
    "# regrid blast data on the simulation time grid by\n",
    "#  1. box car avaraging with kernel delta_t long\n",
    "#  2. decimating at a delta_t cadence\n",
    "#  note: now data have delta_t cadence\n",
    "kernel = np.ones( np.int(delta_t*5) )\n",
    "TM = np.convolve(TM, kernel/kernel.size, mode='same')[kernel.size::kernel.size]\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 5))\n",
    "ax.plot(np.arange(TM.size)*60/3600/25, TM)\n",
    "ax.set_ylabel ( 'Temperature [$^o$C]')\n",
    "ax.set_xlabel('Time [days]')\n",
    "ax.grid()\n",
    "_=_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data trend\n",
    "\n",
    "Here I add a temperature correlated trend to the data using the following prescription\n",
    "\n",
    "1. Select a temperature timeline of length = the time of the observation. This timeline is selected with a random starting time in the BlastPol temperature HK\n",
    "2. Scale the trend peak-to-peak to some value. Below I use 0.1%, but different values should be investigated. \n",
    "3. Add the trend to the data as a multiplicative noise term. The idea being that such trend can change the instrument throughput because of thermoelastic effects. \n",
    "4. The trend is added as \n",
    "$$ [1+g(t)] \\times (F_s + F_p)/F_s \\simeq 1 + g(t) + F_p/F_s$$\n",
    "So the signal we are studying has the form of \n",
    "$$ g(t) + F_p/F_s$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nsim = 1024     # this many simulations\n",
    "noise_std =1e-3 # this value to be replaced with ExoRad's estimate\n",
    "trend_amplitude = 0.001\n",
    "\n",
    "# Repeat Nsim independent observations adding noise to each\n",
    "# Observations are stored in D1's first dimension\n",
    "D1  = np.zeros( (Nsim, tt.size) ) + model\n",
    "D1 += np.random.randn( *D1.shape )*noise_std\n",
    "TData = np.zeros_like(D1)\n",
    "\n",
    "for k in range(D1.shape[0]):\n",
    "    idx0 = np.random.randint(0, high=TM.size  - D1.shape[1])\n",
    "    temp_trend = TM[idx0:idx0+D1.shape[1]].copy()\n",
    "    TData[k] = temp_trend.copy()\n",
    "    temp_trend -= temp_trend.mean()\n",
    "    temp_trend /= np.abs(temp_trend).max()\n",
    "    temp_trend = trend_amplitude*temp_trend\n",
    "    D1[k] += temp_trend\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 5))\n",
    "ax.set_ylabel ( 'Signal')\n",
    "ax.set_xlabel('Time [h]')\n",
    "ax.grid()\n",
    "\n",
    "for k in range(100):\n",
    "    ax.plot(tt/3600, D1[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to see if we can recover the science signal.\n",
    "\n",
    "First, I make the hypothesis that the Earth-synchronous signal is orthogonal to the exoplanet signal. That means, I repeat the same lstsq fit done previously and see what happen..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least-square fit the data\n",
    "A = np.c_[np.sin(2*np.pi*tt/system['Period']), \n",
    "          np.cos(2*np.pi*tt/system['Period']), \n",
    "          np.ones(tt.size)]\n",
    "\n",
    "par, *_ = np.linalg.lstsq(A, D1.T, rcond=-1)\n",
    "\n",
    "# Calculate statistics\n",
    "amplitude = np.sqrt( par[0]**2 + par[1]**2)\n",
    "amplitude_mean = amplitude.mean()\n",
    "amplitude_std  = amplitude.std()\n",
    "amplitude_snr  = amplitude_mean/amplitude_std\n",
    "amplitude_bias = (0.5*eclipse_depth - amplitude_mean)/(0.5*eclipse_depth)\n",
    "amplitude_bias_error = amplitude_std/(0.5*eclipse_depth)/np.sqrt(amplitude.size)\n",
    "TITLE = 'SNR = {:.0f};  BIAS = ({:.2f} +/- {:.2f})%'.format(amplitude_snr, \n",
    "                                           100*amplitude_bias,\n",
    "                                           100*amplitude_bias_error)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 5))\n",
    "ax.hist(100*amplitude)\n",
    "ax.set_xlabel('Amplitude [%]')\n",
    "ax.set_title(TITLE)\n",
    "ax.vlines(0.5*eclipse_depth*100, *ax.get_ylim(), color='r')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This clearly failed. All signals are Nyquist sampled, but we have a large aliasing noise. Perhaps there are ways to deal with that, but I don't know any off-the-top of my head.\n",
    "\n",
    "Awaiting some clever idea, I can then try to fit an Earth-synchronous armonic signal..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.c_[np.sin(2*np.pi*tt/system['Period']), \n",
    "          np.cos(2*np.pi*tt/system['Period']), \n",
    "          np.sin(2*np.pi*tt/(24*3600)), \n",
    "          np.cos(2*np.pi*tt/(24*3600)), \n",
    "          np.ones(tt.size)]\n",
    "\n",
    "par, *_ = np.linalg.lstsq(A, D1.T, rcond=-1)\n",
    "\n",
    "# Calculate statistics\n",
    "amplitude = np.sqrt( par[0]**2 + par[1]**2)\n",
    "amplitude_mean = amplitude.mean()\n",
    "amplitude_std  = amplitude.std()\n",
    "amplitude_snr  = amplitude_mean/amplitude_std\n",
    "amplitude_bias = (0.5*eclipse_depth - amplitude_mean)/(0.5*eclipse_depth)\n",
    "amplitude_bias_error = amplitude_std/(0.5*eclipse_depth)/np.sqrt(amplitude.size)\n",
    "\n",
    "TITLE = 'SNR = {:.0f};  BIAS = ({:.2f} +/- {:.2f})%'.format(amplitude_snr, \n",
    "                                           100*amplitude_bias,\n",
    "                                           100*amplitude_bias_error)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 5))\n",
    "ax.hist(100*amplitude)\n",
    "ax.set_xlabel('Amplitude [%]')\n",
    "ax.set_title(TITLE)\n",
    "ax.vlines(0.5*eclipse_depth*100, *ax.get_ylim(), color='r')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also hasn't worked. Partially because the same aliasing argument of the previous attempt, but perhaps also because the armonic model is not a good one. \n",
    "\n",
    "I can then try to cross-correlate directly with the HK data. Noting, however, that there could be a transfer function between the HK and the effect. This transfer function is unknown at the curent time, but we can say that it is some sort of low-pass filter with some time delay. Not considering it here, implies a significatly, and unrealistic cased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitude = np.zeros(D1.shape[0])\n",
    "\n",
    "for k in range(D1.shape[0]):\n",
    "\n",
    "    A = np.c_[np.sin(2*np.pi*tt/system['Period']), \n",
    "              np.cos(2*np.pi*tt/system['Period']), \n",
    "              TData[k],\n",
    "              np.ones(tt.size)]\n",
    "\n",
    "    par, *_ = np.linalg.lstsq(A, D1[k], rcond=-1)\n",
    "    amplitude[k] = np.sqrt( par[0]**2 + par[1]**2)\n",
    "\n",
    "# Calculate statistics\n",
    "amplitude_mean = amplitude.mean()\n",
    "amplitude_std  = amplitude.std()\n",
    "amplitude_snr  = amplitude_mean/amplitude_std\n",
    "amplitude_bias = (0.5*eclipse_depth - amplitude_mean)/(0.5*eclipse_depth)\n",
    "amplitude_bias_error = amplitude_std/(0.5*eclipse_depth)/np.sqrt(amplitude.size)\n",
    "TITLE = 'SNR = {:.0f};  BIAS = ({:.2f} +/- {:.2f})%'.format(amplitude_snr, \n",
    "                                           100*amplitude_bias,\n",
    "                                           100*amplitude_bias_error)\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(10, 5))\n",
    "ax.hist(100*amplitude)\n",
    "ax.set_xlabel('Amplitude [%]')\n",
    "ax.set_title(TITLE)\n",
    "ax.vlines(0.5*eclipse_depth*100, *ax.get_ylim(), color='r')\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better, but far from ideal. The SNR more than a factor two worse. The bias, however, is not that bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
